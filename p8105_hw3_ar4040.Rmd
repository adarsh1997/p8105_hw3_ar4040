---
title: "Homework 3"
author: Adarsh Ramakrishnan
output: github_document
---

This is my homework 3 solution:


Loading tidyverse library:

```{r libraries}
library(tidyverse)
library(p8105.datasets)
data("instacart")
```


## Problem 1

```{r}
data("instacart")
```

This dataset contants `r nrow(instacart)` rows and xyz columns
Observations are levels of items in order by user. There are user/order variables. -- user id, order id, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric code. 

How many aisles are most items from?

```{r}
instacart %>% count(aisle) %>% arrange(desc(n))
```

Let's make a plot

```{r}
instacart %>% count(aisle) %>% filter(n>10000)%>%
mutate ( aisle = factor(aisle), aisle = fct_reorder(aisle, n)) %>%
ggplot(aes(x = aisle, y = n)) + 
geom_point() + 
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!

```{r}
instacart %>%
    filter(aisle %in% c("baking ingredients","dog food care", "packed vegetable fruits"))%>%
  group_by(aisle) %>%
  count(product_name)%>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle, rank) %>%
  knitr::kable()
```

Apples vs ice cream..

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream"))%>%
  group_by(product_name, order_dow)%>%
  summarise(mean_hour = mean(order_hour_of_day))%>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```


##Problem 2

Import and clean the accel_data csv - 
```{r}
accel_df = read_csv("./data/accel_data.csv")%>% 
janitor::clean_names()%>%
pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_number",
    values_to = "activity_count")%>%
mutate(
    weekday_weekend = case_when(
      day == "Saturday" ~ "weekend",
      day == "Sunday" ~ "weekend",
      day == "Monday" ~ "weekday",
      day == "Tuesday" ~ "weekday",
      day == "Wednesday" ~ "weekday",
      day == "Thursday" ~ "weekday",
      day == "Friday" ~ "weekday",
      TRUE      ~ ""
  ))
```

Creating a table that aggregated activity count for each of the days 

```{r}
accel_df%>%
group_by(day_id)%>%
summarize(total_activity_count = sum(activity_count, na.rm = FALSE))
  
```
Making a plot of 24 hour activity time courses for the different days.

```{r}
accel_df%>%
group_by(day_id)%>%
ggplot(aes(x = ))
```

data wrangling - 
1) go from wide format to long format - activity count, minute of the day
2)straightforward
3)useful names for activity count and minute
4)mutate - weekday and weekend
5)variable classes - num, char, factor (is order reasonable)

point 2-
- table with 35 day, total activity count for those days 
- go with week number and number of days
(group by and summarize)
- what jumps out at you looking at the dataset

point 3-
geom_line() could be useful. Linked lines overlapping each other. 35 lines in the middle of the plot 
aes(color = day of week)

potential issues - 
for the table, day of week would by default be in alphabetical order. May need to use factors to order it correctly 

for tidying, is minute of day in numeric format or some other format? Make sure it is numeric. Later on, the plots need to show what you want to show and be in right order

#Problem 3


point 1
- seperate year, month, and day. No need to convert month to descriptor 
- snowfall units should be converted to good units. degrees C perhaps

point 2 
- data manipulation followed by plotting 
- group by and summarize
- group by station, year, month
- summarize to get average max temperature 
- filter Jan and July (doesn't matter which order)
- use count to look at common snowball values
- plot has lot of lines stacked up on each other.
- Use facet to get two panel plot 

point 3
- tmax vs tmin - contour, bin, or hex plot would be better
- second plot, filter by those values, use boxplot, ridgeplots et c to show distribution 

